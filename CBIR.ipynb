{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBIR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNESKyfer8NLZGmEzp6XZBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riskaseptianaa/Images-Retrieval-140-175/blob/main/CBIR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yI6UWfFe_gVS"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsAKbrI1j2O"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import scipy\n",
        "from IPython import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from skimage.feature import hog\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "import xgboost as xgb\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irLn7nB91kdM",
        "outputId": "2b043e99-c9fe-4bef-96ad-6927532d405e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odP4synn1oXA"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/TKC-new\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXBhqTY61v-t",
        "outputId": "dd820f4d-8a9d-4f7b-a754-8a9ed4f1e20b"
      },
      "source": [
        "%cd /content/gdrive/My Drive/TKC-new"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/TKC-new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RopwDWBP1yA6",
        "outputId": "a562544d-0e0e-4299-a99f-babe891d955b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flowers  flowers.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHWtM-7-10Ju",
        "outputId": "85b346cb-933e-44ed-c57e-440cc799b71a"
      },
      "source": [
        "DATADIR=\"/content/gdrive/MyDrive/TKC-new/flowers\"\n",
        "CATEGORIES=[\"flowers\"]\n",
        "training_data=[]\n",
        "i = 1\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR,category)\n",
        "    class_num=CATEGORIES.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        try:\n",
        "            img_array=cv2.imread(os.path.join(path,img))\n",
        "            new_image=np.asarray(cv2.resize(img_array,(300,300)))\n",
        "            training_data.append([new_image, class_num])\n",
        "            print(\"Gambar termuat : \",i)\n",
        "            display.clear_output(wait=True)\n",
        "            i=i+1\n",
        "        except Exception as e:\n",
        "            pass## Load Image Data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gambar termuat :  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I5NJER7_lnc"
      },
      "source": [
        "## Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdX0234H12LT"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "for image,label in training_data:\n",
        "    X.append(image)\n",
        "    y.append(label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDmB8NjW2FTu"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,stratify=y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeOYClyw2Hd-",
        "outputId": "1c3f96ff-b33a-40ec-a178-5b2e3884bff5"
      },
      "source": [
        "print(\"Jumlah data latih : \",np.shape(X_train)[0])\n",
        "print(\"Jumlah data uji   : \",np.shape(X_test)[0]) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data latih :  80\n",
            "Jumlah data uji   :  20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJsGfy12_q6y"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ffB-8QK2JYG"
      },
      "source": [
        "def preprocessing1(arr):\n",
        "    arr_prep=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        img=cv2.cvtColor(arr[i], cv2.COLOR_BGR2GRAY)\n",
        "        arr_prep.append(img)\n",
        "    return arr_prep\n",
        "\n",
        "def preprocessing2(arr):\n",
        "    arr_prep=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        image=cv2.cvtColor(arr[i], cv2.COLOR_BGR2GRAY)\n",
        "        arr_prep.append(image)\n",
        "    return arr_prep\n",
        "\n",
        "def preprocessing3(arr):\n",
        "    arr_prep=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        image=cv2.cvtColor(arr[i], cv2.COLOR_BGR2HSV)\n",
        "        arr_prep.append(image)\n",
        "    return arr_prep"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22qmGodq_wuS"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv2pxa-12NfA"
      },
      "source": [
        "def FtrExtractHOG(img):\n",
        "    ftr,_=hog(img, orientations=9, pixels_per_cell=(50, 50),\n",
        "            cells_per_block=(2, 2), visualize=True, multichannel=False, block_norm= 'L2')\n",
        "    return ftr\n",
        "\n",
        "def FtrExtractGLCM(img, props, dists=[5], agls=[0, np.pi/4, np.pi/2, 3*np.pi/4], lvl=256, sym=True, norm=True):\n",
        "    glcm = greycomatrix(img, \n",
        "                        distances=dists, \n",
        "                        angles=agls, \n",
        "                        levels=lvl,\n",
        "                        symmetric=sym, \n",
        "                        normed=norm)\n",
        "    feature = []\n",
        "    glcm_props = [propery for name in props for propery in greycoprops(glcm, name)[0]]\n",
        "    for item in glcm_props:\n",
        "            feature.append(item)\n",
        "        \n",
        "    return feature\n",
        "\n",
        "def FtrExtractHSV(img):\n",
        "    chans = cv2.split(img)\n",
        "    features = []\n",
        "\n",
        "    for chan in chans:\n",
        "        hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n",
        "        features.extend(hist)\n",
        "    return np.array(features).flatten()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PqdgUm62Tty"
      },
      "source": [
        "def featureExtraction1(arr):\n",
        "    arr_feature=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        arr_feature.append(FtrExtractHOG(arr[i]))\n",
        "    return arr_feature\n",
        "\n",
        "properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'ASM', 'energy']\n",
        "def featureExtraction2(arr):\n",
        "    arr_feature=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        arr_feature.append(FtrExtractGLCM(arr[i],props=properties))\n",
        "    return arr_feature\n",
        "\n",
        "def featureExtraction3(arr):\n",
        "    arr_feature=[]\n",
        "    for i in range(np.shape(arr)[0]):\n",
        "        arr_feature.append(FtrExtractHSV(arr[i]))\n",
        "    return arr_feature"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daID5hxS_260"
      },
      "source": [
        "## K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFX1VWJ62Wtq"
      },
      "source": [
        "def kfold_1(X_train,y_train,K,stat):\n",
        "\n",
        "  cvscores = []\n",
        "  i = 1\n",
        "  skf = KFold(n_splits=K)\n",
        "\n",
        "  X_train_ = np.array(X_train)\n",
        "  y_train = np.array(y_train)\n",
        "  if (stat==1):\n",
        "      RF = RandomForestClassifier(n_estimators=400, random_state = 42)\n",
        "      for train_index,val_index in skf.split(X_train_):\n",
        "        x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "        y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        RF.fit(x_train_new, y_train_new)\n",
        "\n",
        "        y_pred = RF.predict(x_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "        print(\"%.3f%%\"%(acc*100))\n",
        "        i=i+1\n",
        "        cvscores.append(acc)\n",
        "  elif (stat==2):\n",
        "      DTL = DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=20, random_state=42)\n",
        "      for train_index,val_index in skf.split(X_train_):\n",
        "        x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "        y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        DTL.fit(x_train_new, y_train_new)\n",
        "\n",
        "        y_pred = DTL.predict(x_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "        print(\"%.3f%%\"%(acc*100))\n",
        "        i=i+1\n",
        "        cvscores.append(acc)\n",
        "\n",
        "  elif (stat==3):\n",
        "      XG = xgb.XGBClassifier(subsample=0.8, learning_rate=0.1)\n",
        "      for train_index,val_index in skf.split(X_train_):\n",
        "        x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "        y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "        XG.fit(x_train_new, y_train_new)\n",
        "\n",
        "        y_pred = XG.predict(x_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "        print(\"%.3f%%\"%(acc*100))\n",
        "        i=i+1\n",
        "        cvscores.append(acc)\n",
        "  \n",
        "  return cvscores"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOXuStIG3tj0"
      },
      "source": [
        "X_trainp_shape=preprocessing1(X_train)\n",
        "X_testp_shape=preprocessing1(X_test)\n",
        "\n",
        "X_trainp_texture=preprocessing2(X_train)\n",
        "X_testp_texture=preprocessing2(X_test)\n",
        "\n",
        "X_trainp_color=preprocessing3(X_train)\n",
        "X_testp_color=preprocessing3(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kouczuVh34XR"
      },
      "source": [
        "X_trainftr_shape=featureExtraction1(X_trainp_shape)\n",
        "X_testftr_shape=featureExtraction1(X_testp_shape)\n",
        "\n",
        "X_trainftr_texture=featureExtraction2(X_trainp_texture)\n",
        "X_testftr_texture=featureExtraction2(X_testp_texture)\n",
        "\n",
        "X_trainftr_color=featureExtraction3(X_trainp_color)\n",
        "X_testftr_color=featureExtraction3(X_testp_color)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RLwcxdH36qy"
      },
      "source": [
        "X_trainftr_combined = np.concatenate((X_trainftr_shape,X_trainftr_texture,X_trainftr_color),axis=1)\n",
        "X_testftr_combined = np.concatenate((X_testftr_shape,X_testftr_texture,X_testftr_color),axis=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRKdRGBW3-XX",
        "outputId": "49a18e60-0fe8-4194-947a-e21767b1bc35"
      },
      "source": [
        "print(\"Dimensi fitur bentuk  : \",np.shape(X_trainftr_shape)[1])\n",
        "print(\"Dimensi fitur tekstur : \",np.shape(X_trainftr_texture)[1])\n",
        "print(\"Dimensi fitur warna   : \",np.shape(X_trainftr_color)[1])\n",
        "print(\"Dimensi fitur gabungan: \",np.shape(X_trainftr_combined)[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi fitur bentuk  :  900\n",
            "Dimensi fitur tekstur :  24\n",
            "Dimensi fitur warna   :  768\n",
            "Dimensi fitur gabungan:  1692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHP3Hdj4AMDl"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDUDOdwn5Ma8"
      },
      "source": [
        "X_train = np.array(X_train).astype('float32')\n",
        "X_test = np.array(X_test).astype('float32')\n",
        "\n",
        "mean_image = np.mean(X_train, axis = 0)\n",
        "\n",
        "X_train -= mean_image\n",
        "X_test -= mean_image"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMCq5J8i5Pmk"
      },
      "source": [
        "y_train_binary = to_categorical(y_train)\n",
        "y_test_binary = to_categorical(y_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EamY5-35R6w"
      },
      "source": [
        "def create_inception_model():\n",
        "  model = InceptionV3(weights=None, include_top=False, input_shape=(300, 300, 3), pooling='max')\n",
        "  x = model.output\n",
        "  predictions = Dense(1, activation='softmax')(x)\n",
        "  myModel_scratch = Model(inputs=model.input, outputs=predictions, name='InceptionV3')\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  myModel_scratch.compile(optimizer=opt,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return myModel_scratch"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iGQJyI35UuI"
      },
      "source": [
        "def kfold_2(X_train,y_train,K):\n",
        "\n",
        "  model_validation=create_inception_model()\n",
        "  cvscores = []\n",
        "  i = 1\n",
        "  skf = KFold(n_splits=K)\n",
        "\n",
        "  X_train_ = np.array(X_train)\n",
        "  y_train = np.array(y_train)\n",
        "  for train_index,val_index in skf.split(X_train_):\n",
        "    x_train_new,x_val=X_train_[train_index],X_train_[val_index]\n",
        "    y_train_new,y_val=y_train[train_index],y_train[val_index]\n",
        "\n",
        "    model_validation.fit(x_train_new, y_train_new, validation_data = (x_val,y_val), epochs=20, verbose=0)\n",
        "\n",
        "    scores = model_validation.evaluate(x_val, y_val, verbose=0)\n",
        "    # print(\"Fold ke\",i,\" -> \",scores[1]*100,\"%\")\n",
        "    print(\"Fold ke\",i,\" -> \",end=\" \")\n",
        "    print(\"%.3f%%\"%(scores[1]*100))\n",
        "    i=i+1\n",
        "    cvscores.append(scores[1])\n",
        "\n",
        "  return cvscores"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBSVQM1_BOCN",
        "outputId": "9c159997-4001-454b-a5fa-106350c61c34"
      },
      "source": [
        "model = create_inception_model()\n",
        "model.fit(X_train, y_train_binary,epochs=5)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3/3 [==============================] - 69s 18s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 61s 18s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 61s 18s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 61s 18s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 61s 18s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe23ff02750>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVYpqDKq_UZs",
        "outputId": "a83555ac-b894-4df8-8a60-afe0d2c3e3a9"
      },
      "source": [
        "predictions = model.predict(X_test , batch_size = 32).argmax(axis = 1)\n",
        "print(classification_report(y_test_binary.argmax(axis = 1), predictions))\n",
        "print(confusion_matrix(y_test_binary.argmax(axis = 1), predictions))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        20\n",
            "\n",
            "    accuracy                           1.00        20\n",
            "   macro avg       1.00      1.00      1.00        20\n",
            "weighted avg       1.00      1.00      1.00        20\n",
            "\n",
            "[[20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwGU9C-0HdKX",
        "outputId": "8b85ff2c-44f3-40e0-9394-95651c831fd4"
      },
      "source": [
        "accuracy = model.evaluate(X_test, y_test_binary, verbose=1)\n",
        "print('Test loss    :', accuracy[0])\n",
        "print('Test accuracy: %.2f%%' % (accuracy[1]*100))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test loss    : 0.0\n",
            "Test accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}